{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import matplotlib.pyplot\n",
    "from mpl_finance import candlestick_ohlc\n",
    "import dateutil.parser as dparser\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipp(list1, list2):\n",
    "    a = len(list1)\n",
    "    b = len(list2)\n",
    "    return [[list1[i], list2[i]] for i in range(min(a, b))]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, n, currentyear):\n",
    "    \"\"\"This functions scrapes the NASDAQ newsfeed for article links \"\"\"\n",
    "    Pairs = []\n",
    "    for i in range(1, n + 1):\n",
    "        if i == 1:\n",
    "            url = \"https://www.nasdaq.com/symbol/\" + query + \"/news-headlines\"\n",
    "        else:\n",
    "            url = \"https://www.nasdaq.com/symbol/\" + query + \"/news-headlines?page=\" + str(i)\n",
    "    \n",
    "        page = requests.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "        links = soup.findAll('a')\n",
    "        dates = soup.findAll('small')\n",
    "    \n",
    "        Article_list = []\n",
    "        Date_list = []\n",
    "    \n",
    "        \"\"\"\n",
    "        Get all the links for the articles from the NASDAQ newsfeed\n",
    "        \"\"\"\n",
    "        counter = 0\n",
    "    \n",
    "        for link in links:\n",
    "            article = link.get('href')\n",
    "            if (\"/article/\" in article):\n",
    "                if counter > 5:\n",
    "                    Article_list.append(article)\n",
    "                counter += 1\n",
    "\n",
    "        \"\"\"\n",
    "        Get all the dates for the articles\n",
    "        \"\"\"\n",
    "    \n",
    "        for date in dates:\n",
    "            text = date.get_text()\n",
    "            if \"/\" + currentyear in text:\n",
    "                Date_list.append(text[24:33])\n",
    "    \n",
    "        Pairs.extend(zipp(Article_list, Date_list))\n",
    "    \"\"\"\n",
    "    # Print suite for debugging\n",
    "    for p in Pairs:\n",
    "        print(p)\n",
    "    print(len(Pairs))\n",
    "    \"\"\"\n",
    "    \n",
    "    return Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keywords(keywords, url):\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    text = soup.get_text().lower()\n",
    "    \n",
    "    number = 0\n",
    "    for k in keywords:\n",
    "        number += len(re.findall(r'(?=' + k.lower() + ')', text))\n",
    "    return number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(Pairs, keywords):\n",
    "    plot_vals = []\n",
    "    for p in Pairs:\n",
    "        new_pair = [dparser.parse(p[1], fuzzy=True), count_keywords(keywords, p[0])]\n",
    "        plot_vals.append(new_pair)\n",
    "    return plot_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(query):\n",
    "    url = \"https://www.nasdaq.com/symbol/\" + query + \"/historical\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    stock_data = []\n",
    "    \n",
    "    chart = soup.find(\"tbody\")\n",
    "    days = chart.findAll(\"tr\")\n",
    "    for day in days:\n",
    "        data = day.findAll(\"td\")\n",
    "        text_data = [d.get_text() for d in data]\n",
    "        clean_data = [text[35:].split('\\r')[0] for text in text_data]\n",
    "        \n",
    "        stock_data.append(clean_data)\n",
    "        \n",
    "    stock_data = stock_data[1:]\n",
    "    for s in stock_data:\n",
    "            s[0] = dparser.parse(s[0])\n",
    "            for i in range(1,5):\n",
    "                s[i] = float(s[i])\n",
    "            s[5] = s[5].replace(',','')\n",
    "            s[5] = int(s[5])\n",
    "    return stock_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_counts(plot_vals):\n",
    "    new_date_list = []\n",
    "    for p in plot_vals:\n",
    "        if p[0] not in new_date_list:\n",
    "            new_date_list.append(p[0])\n",
    "    size = len(new_date_list)\n",
    "    new_count_list = [0]*size\n",
    "    for i in range(size):\n",
    "        for p in plot_vals:\n",
    "            if new_date_list[i] == p[0]:\n",
    "                new_count_list[i] += p[1]\n",
    "    return zipp(new_date_list, new_count_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_scrape(query, keywords, n=1, currentyear=\"2019\"):\n",
    "    data = search(query, n, currentyear)\n",
    "    processed_data = process_data(data, keywords)\n",
    "    return sum_counts(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = keyword_scrape(\"AAPL\", [\"new\", \"tablet\"], n=3)\n",
    "stock = get_stock_data(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot keyword occurences vs date\n",
    "def plot_keyword_occurences(data):\n",
    "    xlist = [d[0] for d in data]\n",
    "    ylist = [d[1] for d in data]\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "    plt.bar(xlist,ylist)\n",
    "    plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stock data for past 3 months\n",
    "# stock data = [date, open, high, low, close, volume]\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_candles(stock):\n",
    "    # option is int 0 to 4\n",
    "    stock_data = [[mdates.date2num(s[0]), s[1], s[2], s[3], s[4]] for s in stock]\n",
    "    stride = 4\n",
    "    fig = plt.figure(figsize=[25,10], dpi=300)\n",
    "    \n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    candlestick_ohlc(ax1,stock_data,width=0.8,colorup='#77d879', colordown='#db3f3f') \n",
    "    \n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    for n, label in enumerate(ax1.xaxis.get_ticklabels()):\n",
    "        if n % stride != 0:\n",
    "            label.set_visible(False)\n",
    "            \n",
    "def plot_volume(stock):\n",
    "    dates = [s[0] for s in stock]\n",
    "    volume_data = [s[5] for s in stock]\n",
    "    \n",
    "    fig = plt.figure(figsize=[25,10], dpi=300)\n",
    "    \n",
    "    ax1 = fig.add_subplot(111)\n",
    "    \n",
    "    plt.bar(dates, volume_data)\n",
    "    \n",
    "    stride = 4\n",
    "    \n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    for n, label in enumerate(ax1.xaxis.get_ticklabels()):\n",
    "        if n % stride != 0:\n",
    "            label.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keyword_occurences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stocks(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_volume(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
